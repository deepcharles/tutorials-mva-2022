{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Machine Learning for Time Series (Master MVA)**\n",
    "\n",
    "- Tutorial 3, Friday 11<sup>th</sup> February 2021\n",
    "- [Link to the class material.](http://www.laurentoudre.fr/ast.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this tutorial, we illustrate the following concepts:\n",
    "\n",
    "- signal prediction,\n",
    "- model a signal in trend, seasonality and stationary process,\n",
    "- the AR and MA processes,\n",
    "- the singular spectrum analysis (SSA)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from loadmydata.load_nyc_taxi import load_nyc_taxi_dataset\n",
    "from numpy.fft import rfft, rfftfreq\n",
    "from numpy.polynomial.polynomial import Polynomial\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.signal import argrelmax, periodogram\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.arima_process import arma_generate_sample\n",
    "from statsmodels.tsa.stattools import acf, adfuller, kpss, pacf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Utility functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from numpy.lib.stride_tricks import \\\n",
    "        sliding_window_view  # New in version 1.20.0\n",
    "\n",
    "    def get_trajectory_matrix(arr, window_shape, jump=1):\n",
    "        return sliding_window_view(x=arr, window_shape=window_shape)[::jump]\n",
    "\n",
    "\n",
    "except ImportError:\n",
    "\n",
    "    def get_trajectory_matrix(arr, window_shape, jump=1):\n",
    "        n_rows = ((arr.size - window_shape) // jump) + 1\n",
    "        n = arr.strides[0]\n",
    "        return np.lib.stride_tricks.as_strided(\n",
    "            arr, shape=(n_rows, window_shape), strides=(jump * n, n)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fig_ax(figsize=(15, 4)):\n",
    "    return plt.subplots(figsize=figsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_largest_local_max(\n",
    "    signal1D: np.ndarray, n_largest: int = 3, order: int = 1\n",
    ") -> [np.ndarray, np.ndarray]:\n",
    "    \"\"\"Return the largest local max and the associated index in a tuple.\n",
    "\n",
    "    This function uses `order` points on each side to use for the comparison.\n",
    "    \"\"\"\n",
    "    all_local_max_indexes = argrelmax(signal1D, order=order)[0]\n",
    "    all_local_max = np.take(signal1D, all_local_max_indexes)\n",
    "    largest_local_max_indexes = all_local_max_indexes[\n",
    "        all_local_max.argsort()[::-1]\n",
    "    ][:n_largest]\n",
    "\n",
    "    return (\n",
    "        np.take(signal1D, largest_local_max_indexes),\n",
    "        largest_local_max_indexes,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adf_test(timeseries):\n",
    "    print(\"Results of Dickey-Fuller Test:\")\n",
    "    dftest = adfuller(timeseries, autolag=\"AIC\")\n",
    "    dfoutput = pd.Series(\n",
    "        dftest[0:4],\n",
    "        index=[\n",
    "            \"Test Statistic\",\n",
    "            \"p-value\",\n",
    "            \"#Lags Used\",\n",
    "            \"Number of Observations Used\",\n",
    "        ],\n",
    "    )\n",
    "    for key, value in dftest[4].items():\n",
    "        dfoutput[\"Critical Value (%s)\" % key] = value\n",
    "    print(dfoutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kpss_test(timeseries):\n",
    "    print(\"Results of KPSS Test:\")\n",
    "    kpsstest = kpss(timeseries, regression=\"c\", nlags=\"auto\")\n",
    "    kpss_output = pd.Series(\n",
    "        kpsstest[0:3], index=[\"Test Statistic\", \"p-value\", \"Lags Used\"]\n",
    "    )\n",
    "    for key, value in kpsstest[3].items():\n",
    "        kpss_output[\"Critical Value (%s)\" % key] = value\n",
    "    print(kpss_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_anti_diag(traj_matrix: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Average anti diagonal elements of a 2d array\"\"\"\n",
    "    x1d = [\n",
    "        np.mean(traj_matrix[::-1, :].diagonal(i))\n",
    "        for i in range(-traj_matrix.shape[0] + 1, traj_matrix.shape[1])\n",
    "    ]\n",
    "    return np.array(x1d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, _, description = load_nyc_taxi_dataset()\n",
    "print(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = fig_ax()\n",
    "_ = X.plot(x=\"timestamp\", y=\"taxi_count\", ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "    <p><b>Question</b></p>\n",
    "    <p>Plot the taxi count for October and 2014-10-12.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily count\n",
    "\n",
    "In this tutorial, we are interested in the evolution in the **daily** count.\n",
    "To that end, we resample the original signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_taxi_count = X.resample(\"1D\", on=\"timestamp\").sum()\n",
    "daily_taxi_count_np = daily_taxi_count.to_numpy().squeeze()\n",
    "fig, ax = fig_ax()\n",
    "ax.plot(daily_taxi_count, \"*-\")\n",
    "_ = ax.set_ylim(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "    <p><b>Question</b></p>\n",
    "    <p>Plot the daily count in October 2014. What can you observe?</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "    <p><b>Question</b></p>\n",
    "    <p>Plot or print the average count per day of the week. Which day is the busiest?</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signal Prediction\n",
    "\n",
    "The objective is to predict the daily taxi for the next two weeks (14 days).\n",
    "First, we prepare the training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_pred = 14  # predict the next 14 samples\n",
    "\n",
    "# train/test split\n",
    "signal_train, signal_pred = np.split(\n",
    "    daily_taxi_count_np.astype(float), [-n_samples_pred]\n",
    ")\n",
    "n_samples = n_samples_train = signal_train.size\n",
    "\n",
    "# scaling\n",
    "scaler = StandardScaler().fit(signal_train.reshape(-1, 1))\n",
    "signal_train = scaler.transform(signal_train.reshape(-1, 1)).flatten()\n",
    "signal_pred = scaler.transform(signal_pred.reshape(-1, 1)).flatten()\n",
    "\n",
    "# keep the indexes of train and test (for plotting mostly)\n",
    "time_array_train, time_array_pred = np.split(\n",
    "    np.arange(daily_taxi_count_np.size), [-n_samples_pred]\n",
    ")\n",
    "time_array = time_array_train\n",
    "calendar_time_array = daily_taxi_count.iloc[time_array].index.to_numpy()\n",
    "\n",
    "# plot\n",
    "fig, ax = fig_ax()\n",
    "ax.plot(time_array_train, signal_train, \"-*\", label=\"Train\")\n",
    "ax.plot(time_array_pred, signal_pred, \"-*\", label=\"To predict\")\n",
    "_ = plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trend\n",
    "\n",
    "Three trend estimation methods are tested:\n",
    "\n",
    "- constant trend,\n",
    "- linear trend,\n",
    "- polynomial trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = fig_ax()\n",
    "ax.plot(signal_train, label=\"Original\")\n",
    "\n",
    "level = signal_train.mean()  # should be zero\n",
    "approx_trend = level * np.ones(signal_train.size)\n",
    "ax.plot(approx_trend, label=\"Constant trend\")\n",
    "ax.set_title(f\"MSE: {(signal_train-approx_trend).var():.2f}\")\n",
    "_ = plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "    <p><b>Question</b></p>\n",
    "    <p>Plot the best linear approximation of the signal. What is the associated MSE?</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "    <p><b>Question</b></p>\n",
    "    <p>In the previous cell, show the trend predicted by the polynomial fit in the next 14 samples. What do you conclude?</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "    <p><b>Question</b></p>\n",
    "    <p>To conclude, which trend do you choose?</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seasonality\n",
    "\n",
    "The seasonality is the periodical component in the signal at hand.\n",
    "\n",
    "**Finding the harmonic frequencies.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "    <p><b>Question</b></p>\n",
    "    <p>Give two ways to estimate the presence of seasonalities.</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_per_week = 7\n",
    "\n",
    "fourier = abs(rfft(signal_train)) ** 2\n",
    "freqs = rfftfreq(n=n_samples, d=1 / n_samples_per_week)\n",
    "\n",
    "fig, ax = fig_ax()\n",
    "ax.plot(freqs, fourier)\n",
    "ax.set_xlabel(\"Frequency (1/week)\")\n",
    "_ = ax.set_ylabel(\"Fourier coefficient\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DFT is not a consistent estimator of the power spectral density.\n",
    "In practice, the periodogram (or any other variations) is prefered: the DTF is computed over several (possibly overlapping) windows and averaged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_per_week = 7\n",
    "\n",
    "# compute the periodogram\n",
    "freqs, Pxx_spec = periodogram(\n",
    "    x=signal_train,\n",
    "    fs=n_samples_per_week,\n",
    "    window=\"flattop\",\n",
    "    nfft=32 * n_samples_per_week,\n",
    ")\n",
    "spectral_density = np.sqrt(Pxx_spec)\n",
    "\n",
    "# find the main frequencies\n",
    "values, (f_1_ind, f_2_ind) = get_largest_local_max(\n",
    "    spectral_density, n_largest=2\n",
    ")\n",
    "(f_1, f_2) = np.take(freqs, (f_1_ind, f_2_ind))\n",
    "print(\n",
    "    f\"The main periods are {7/f_1:.1f} day{'s' if 7/f_1>1 else ''} and {7/f_2:.1f} day{'s' if 7/f_2>1 else ''}.\"\n",
    ")\n",
    "\n",
    "# plotting\n",
    "fig, ax = fig_ax()\n",
    "ax.plot(freqs, spectral_density)\n",
    "ax.scatter([f_1, f_2], values, color=\"r\")\n",
    "ax.set_xlabel(\"Frequency (1/week)\")\n",
    "_ = ax.set_ylabel(\"Power spectral density\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "    <p><b>Question</b></p>\n",
    "    <p>Modify the code above to estimate the main seasonality from the <b>original</b> signal. What do you conclude?</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Harmonic regression**\n",
    "\n",
    "In an harmonic regression (with two harmonic components), the signal is modelled as follows:\n",
    "$$\n",
    "y_t = \\mu + A_1\\cos(2\\pi f_1 t + \\phi_1) + A_2\\cos(2\\pi f_2 t + \\phi_2) + \\epsilon_t\n",
    "$$\n",
    "\n",
    "where $\\mu, A, \\phi\\in\\mathbb{R}$ must be estimated, the frequencies $f_1$ and $f_2$ are given, and $\\epsilon_t$ is a white noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "    <p><b>Question</b></p>\n",
    "    <p>How can you rewrite this problem as a linear regression problem?</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "    <p><b>Question</b></p>\n",
    "    <p>Code the harmonic regression with the two previously estimated frequencies and show the final fit, the residual signal and the MSE.</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Studying the residual signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A simulated example\n",
    "\n",
    "Simulate a MA(2) process and an AR(2) process.\n",
    "For each plot the autocorrelation and partial autocorrelation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "arparams = np.array([0.55, -0.25])\n",
    "maparams = np.array([0.65, 0.35])\n",
    "\n",
    "ar = np.r_[1, -arparams]  # add zero-lag and negate\n",
    "ma = np.r_[1, maparams]  # add zero-lag\n",
    "\n",
    "\n",
    "n_samples_simulated = 1000\n",
    "ar2 = arma_generate_sample(ar, [1], n_samples_simulated)\n",
    "ma2 = arma_generate_sample([1], ma, n_samples_simulated)\n",
    "\n",
    "fig, ax = fig_ax()\n",
    "ax.plot(ar2, label=\"AR(2)\")\n",
    "ax.plot(ma2, label=\"MA(2)\")\n",
    "_ = plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, (ax_0, ax_1) = plt.subplots(1, 2, figsize=(20, 4))\n",
    "_ = plot_acf(ar2, ax=ax_0, title=\"Autocorrelation AR(2)\")\n",
    "_ = plot_pacf(ar2, ax=ax_1, title=\"Partial autocorrelation AR(2)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, (ax_0, ax_1) = plt.subplots(1, 2, figsize=(20, 4))\n",
    "_ = plot_acf(ma2, ax=ax_0, title=\"Autocorrelation MA(2)\")\n",
    "_ = plot_pacf(ma2, ax=ax_1, title=\"Partial autocorrelation MA(2)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "    <p><b>Question</b></p>\n",
    "    <p>What would be a procedure to estimate the AR and MA order of a process?</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back to our problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "    <p><b>Question</b></p>\n",
    "    <p>Plot the autocorrelation and partial autocorrelation of the residual signal (without the constant and harmonic trend).</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax_0, ax_1) = plt.subplots(1, 2, figsize=(20, 4))\n",
    "_ = plot_acf(residual_signal, ax=ax_0)\n",
    "_ = plot_pacf(residual_signal, ax=ax_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we fit an ARMA process on the residual signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma_order = ...\n",
    "ar_order = ...\n",
    "\n",
    "res = ARIMA(residual_signal, order=(ar_order, 0, ma_order)).fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the fitted model, it is now possible to predict the value of the residual signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_sample_pred = res.predict()\n",
    "out_sample_pred = res.forecast(n_samples_pred)\n",
    "\n",
    "fig, ax = fig_ax()\n",
    "ax.plot(time_array_train, residual_signal, label=\"True residual\")\n",
    "ax.plot(time_array_train, in_sample_pred, label=\"In-sample prediction\")\n",
    "ax.plot(time_array_pred, out_sample_pred, label=\"Out-of-sample prediction\")\n",
    "_ = plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "    <p><b>Question</b></p>\n",
    "    <p>Make and plot the final prediction for the taxi count (not normalized) for the next two weeks, using the trend, seasonal and residual processes.</p>\n",
    "    <p>What do you conclude?</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stationarity checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As was previously seen, the residual signal was not completely stationary since it still contained seasonal and low frequency components.\n",
    "To assess this intuition, several statistical tests exists. Two of the most well-known are:\n",
    "\n",
    "- the Dickey-Fuller test (H0: the signal has a unit root); \n",
    "- the Kwiatkowski–Phillips–Schmidt–Shin (KPSS) test (H0: the signal is trend/level stationary vs H1:the signal has a unit root).\n",
    "\n",
    "Actually, they do not test for stationarity but for symptoms of non-stationarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf_test(residual_signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "    <p><b>Question</b></p>\n",
    "    <p>What can you conclude from the test?</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manage complex trend and outliers with SSA\n",
    "\n",
    "With Singular Spectrum Analysis (SSA), it is possible to manage the low frequency trends and seasonnal effects with the same procedure.\n",
    "SSA is often described as a \"PCA for signals\".\n",
    "\n",
    "Let $y = \\{y_t\\}_t$ denote a $T$-sample long univariate signal, and $L$ a window length.\n",
    "The trajectory matrix $X$ is formed by  $M$ lag-shifted copies of $y$, i.e.\n",
    "\n",
    "$$\n",
    "X:=\n",
    "\\begin{bmatrix}\n",
    "y_1&y_2&y_3&\\ldots&y_{L}\\\\\n",
    "y_2&y_3&y_4&\\ldots&y_{L+1}\\\\\n",
    "y_3&y_4&y_5&\\ldots&y_{L+2}\\\\\n",
    "\\vdots&\\vdots&\\vdots&\\ddots&\\vdots\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "Now, write the Singular Value Decomposition (SVD) of $X$ is as follows:\n",
    "\n",
    "$$\n",
    "X = U\\Sigma V^T = \\sum_{i=1}^{L} X_i\\quad\\text{with}\\quad X_i:= \\sigma_i u_i v_i^T\n",
    "$$\n",
    "\n",
    "where $\\sigma=\\text{diag}(\\sigma_1,\\dots,\\sigma_L)$ are the singular values sorted in descending order, $u_i$ and $v_i$ are respectively the associated left and right singular vectors corresponding to the columns of the orthogonal matrices $U$ and $V$.\n",
    "Each $X_i$ is itself a trajectory matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "    <p><b>Question</b></p>\n",
    "    <p>For a signal of length $T$ and a window of length $L$, what are the dimensions of the trajectory matrix (number of rows and columns)?</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "    <p><b>Question</b></p>\n",
    "    <p>How can you go from a trajectory matrix to a signal?</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us apply apply SSA on the signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_shape = 14\n",
    "trajectory_matrix = get_trajectory_matrix(signal_train, window_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVD\n",
    "u, eigenvals, vh = np.linalg.svd(trajectory_matrix, full_matrices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(eigenvals, \"-*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssa_decomposition = np.zeros((signal_train.size, window_shape))\n",
    "\n",
    "for (ind, (left, sigma, right)) in enumerate(zip(u.T, eigenvals, vh)):\n",
    "    ssa_decomposition.T[ind] = average_anti_diag(\n",
    "        sigma * np.dot(left.reshape(-1, 1), right.reshape(1, -1))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax_arr = plt.subplots(\n",
    "    nrows=window_shape // 3 + 1,\n",
    "    ncols=3,\n",
    "    figsize=(20, 3 * (window_shape // 3 + 1)),\n",
    ")\n",
    "\n",
    "for (ind, (component, ax)) in enumerate(\n",
    "    zip(ssa_decomposition.T, ax_arr.flatten())\n",
    "):\n",
    "    ax.plot(component)\n",
    "    ax.set_xlim(0, component.size)\n",
    "    ax.set_ylim(-2, 2)\n",
    "    ax.set_title(f\"Component n°{ind}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In pratice, the trend (a slowly varying component), the periodic components and noise are well separated by SSA.\n",
    "\n",
    "We can plot the successive reconstructions when adding one SSA component at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax_arr = plt.subplots(\n",
    "    nrows=window_shape // 3 + 1,\n",
    "    ncols=3,\n",
    "    figsize=(20, 3 * (window_shape // 3 + 1)),\n",
    ")\n",
    "\n",
    "reconstruction = np.zeros(signal_train.size)\n",
    "\n",
    "for component, ax in zip(ssa_decomposition.T, ax_arr.flatten()):\n",
    "    reconstruction += component\n",
    "    ax.plot(signal_train)\n",
    "    ax.plot(reconstruction)\n",
    "    ax.set_xlim(0, reconstruction.size)\n",
    "    ax.set_ylim(-5, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grouping**\n",
    "\n",
    "Notice that several SSA components are very similar.\n",
    "Usually they are summed together to deacrease the dimension of the representation.\n",
    "This operation is called \"grouping\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "    <p><b>Question</b></p>\n",
    "    <p>As in the previous tutorial, use a hierarchical clustering approach to group the SSA components together. (use the Euclidean distance and plot the associated dendogram.)</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "    <p><b>Question</b></p>\n",
    "    <p>Report the groups that you found in the <tt>groups</tt> variable.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us plot each SSA group individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping\n",
    "grouped_ssa = np.zeros((signal_train.size, len(groups)))\n",
    "\n",
    "for (dim_ind, component_indexes) in enumerate(groups):\n",
    "    grouped_ssa.T[dim_ind] = np.take(\n",
    "        ssa_decomposition, component_indexes, axis=-1\n",
    "    ).sum(axis=1)\n",
    "\n",
    "fig, ax = fig_ax()\n",
    "_ = ax.plot(grouped_ssa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prediction**\n",
    "\n",
    "The SSA components are then individually extrapolated by fitting an autoregressive model.\n",
    "The extended components are summed to produce the forecast values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "    <p><b>Question</b></p>\n",
    "    <p>Make and plot the final prediction for the taxi count (not normalized) for the next two weeks, by fitting an AR(8) process (use <tt>AutoReg(signal_train, lags=8)</tt>) to each SSA component and summing the forecasts.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = fig_ax((20, 4))\n",
    "\n",
    "ax.plot(\n",
    "    time_array_train, scaler.inverse_transform(signal_train.reshape(-1, 1)), label=\"Train\"\n",
    ")\n",
    "ax.plot(\n",
    "    time_array_pred, scaler.inverse_transform(signal_pred.reshape(-1, 1)), label=\"To predict\"\n",
    ")\n",
    "ax.plot(\n",
    "    time_array_pred,\n",
    "    scaler.inverse_transform(prediction.sum(axis=1).reshape(-1, 1)),\n",
    "    label=\"Predicted\",\n",
    ")\n",
    "\n",
    "\n",
    "_ = plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "    <p><b>Question</b></p>\n",
    "    <p>Conclude. (Is it better or worse than the previous approach? What can we do to improve the results? What is the limitation?)</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
